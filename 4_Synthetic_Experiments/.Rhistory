#' This function is used to estimate the multi-taper periodogram for a specified frequency of interest.
#' @param data Input data of specified structure.
#' @param omega Specified frequency of interest.
#' @param Big_T Time horizon of the data.
#' @return Periodogram estimate of dimension p x p
#' @export
img=sqrt(as.complex(-1)) #imaginary number i^2=-1
H_omega = (Big_T/sqrt(Big_T)) * exp((-img*omega*Big_T)/2) * sinc((omega*Big_T)/2) #FT of Taper
p = length(data) #dimensionality
m = length(data[[1]]) #trials
N_t = NULL;
N_t = rep(list(N_t), m); bar_d = N_t; I = list();
for(j in 1:m){
for(i in 1:p){
N_t[[j]][i] = length(data[[i]][[j]])
bar_d[[j]][i] = (1/sqrt(Big_T) * sum(exp(-img*omega*data[[i]][[j]])) ) - ((N_t[[j]][i]/Big_T) * H_omega )
}
I[[j]] = (outer((bar_d[[j]]), Conj(bar_d[[j]])))/(2*pi)
}
p1 = Reduce("+", I)/length(I)
return(p1)
}
# Theoretical Spectra
uni_hawkes = function(nu,alpha,beta, omega){
t1= nu*beta
t2 = 2*pi*(beta-alpha)
t3 = alpha*(2*beta-alpha)
t4 = ( (beta-alpha)^2 ) + omega^2
f = (t1/t2)*(1+(t3/t4))
return(f)
}
omega = 2*pi*seq(1,500)
omega = omega/200
f = unlist(lapply(omega, function(x) uni_hawkes(1,0.5,0.55, x)))
x1 = list(simulateHawkes(1, 0.5, 0.55,100)) #need list format for periodogram function to work
p1 = unlist(lapply(omega, function(x) periodogram(x1,x,100)))
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l')
lines(omega,f, col="red", lwd=2)
comp2 = list(list(comp))
p2 = unlist(lapply(omega, function(x) periodogram(comp2,x,10)))
plot(omega, p1, xlab=expression(omega), ylab="Spectrum",  type='l')
p2 = unlist(lapply(omega, function(x) periodogram(comp2,x,10)), ylim=c(0,20))
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l')
lines(omega,f, col="red", lwd=2)
comp2 = list(list(comp))
p2 = unlist(lapply(omega, function(x) periodogram(comp2,x,10)))
plot(omega, p1, xlab=expression(omega), ylab="Spectrum",  type='l',  ylim=c(0,20))
lines(omega,f, col="red", lwd=2)
plot(omega, p2, xlab=expression(omega), ylab="Spectrum",  type='l',  ylim=c(0,20))
lines(omega,f, col="red", lwd=2)
lines(omega,1/(2*pi), col="blue", lwd=2)
lines(omega,rep(1/(2*pi), length(omega)), col="blue", lwd=2)
lines(omega,rep(1), length(omega)), col="blue", lwd=2)
lines(omega,rep(1, length(omega)), length(omega)), col="blue", lwd=2)
lines(omega,rep(1, length(omega), length(omega)), col="blue", lwd=2)
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l')
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l', main = "N(t)")
lines(omega,f, col="red", lwd=2)
legend("topright", c("Estimated", "Theoretical"), lty=c(1,1), col=c("black", "red"))
legend("topright", c("Estimated", "Theoretical"), lty=c(1,1), col=c("black", "red"), cex=0.5)
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l', main = "N(t)")
plot(omega, p1, xlab=expression(omega), ylab="Spectrum", ylim=c(0,20), type='l', main = "N(t)")
lines(omega,f, col="red", lwd=2)
legend("topright", c("Estimated", "Theoretical"), lty=c(1,1), col=c("black", "red"), cex=0.8)
p2 = unlist(lapply(omega, function(x) periodogram(comp2,x,10)))
plot(omega, p2, xlab=expression(omega), ylab="Spectrum",  type='l',  ylim=c(0,20))
lines(omega,rep(1/(2*pi), length(omega), length(omega)), col="blue", lwd=2)
plot(omega, p2, xlab=expression(omega), ylab="Spectrum",  type='l',  ylim=c(-1,5))
lines(omega,rep(1/(2*pi), length(omega), length(omega)), col="blue", lwd=2)
# time transform for stationary process
library(Matrix)
library(phonTools)
library(QZ)
library(purrr)
library(matrixStats)
library(complexplus)
library(psych)
library(pracma)
library(hawkes)
library(latex2exp)
library(igraph)
library(hawkes)
# simulate from univariate hawkes
set.seed(5)
# simulate from univariate hawkes
set.seed(5)
alpha = 0.2
beta = 0.4
nu = 0.4
big_t = 100
x = simulateHawkes(nu, alpha, beta, big_t)
# plot process
plot(x[[1]], rep(1, length(x[[1]])), xlab = "t", ylab = "N(t)", main ="Simualted Hawkes Process" )
lambda_t = function(nu, alpha, beta, t, t_i) {
out = nu + sum(alpha*exp(-beta*(t-t_i[t_i<t])))
return(out)
}
z = seq(0, big_t, by = 0.01)
lams=NULL;
for (i in 1:length(z)){
lams[i] = lambda_t(nu, alpha, beta, z[i], x[[1]])
}
plot(z,lams, type="l", ylab = expression(lambda(t)), xlab="t", main = "Intensity Function", ylim=c(0, 10))
points(x[[1]], rep(0, length(x[[1]])), col="red" )
plot(z,lams, type="l", ylab = expression(lambda(t)), xlab="t", main = "Intensity Function", ylim=c(0, 5))
plot(z,lams, type="l", ylab = expression(lambda(t)), xlab="t", main = "Intensity Function", ylim=c(0, 2))
points(x[[1]], rep(0, length(x[[1]])), col="red" )
# Read in simulated data
# Recall that p = 10 and beta is tri-diagonal with rho=0.4 and beta_0 = 0.2
y <- readRDS("~/luna/GLM/simulated_data.RDS")
plot(y[1,][1:50], xlab = "Time", ylab="", main= "Simulated Data for first 50 Time points (Unit 1)")
p = 10 #dimensions
i = 1 # look at dimension 1 first
yt = y[i,][2:9000] # use  8999 values
y_t_minus_1 = y[,(1:8999)] #i.e. y_{t-1} - matrix of predictors (for all p - p x N matrix)
dim(y_t_minus_1)
dim(t(y_t_minus_1))
# Own implementation
# Read in simulated data
# Recall that p = 10 and beta is tri-diagonal with rho=0.4 and beta_0 = 0.2
data <- readRDS("~/luna/GLM/simulated_data.RDS")
# Plot data from dimension 1
#plot(data[1,][1:50], xlab = "Time", ylab="", main= "Simulated Data for first 50 Time points (Unit 1)")
p = 10 #dimensions
i = 1 # look at dimension 1 first
Y = data[i,][2:9000] # use  8999 values
x = y[,(1:8999)] #i.e. y_{t-1} - matrix of predictors (for all p - p x N matrix)
x = Y[,(1:8999)] #i.e. y_{t-1} - matrix of predictors (for all p - p x N matrix)
x = data[,(1:8999)] #i.e. y_{t-1} - matrix of predictors (for all p - p x N matrix)
x = t(x)
dim(x)
x[1,]
# Take lambda as input
lams <- readRDS("~/luna/GLM/lambda.RDS")
lam1 = lams[1]
lam1
length(Y)
dim(x)
library(purrr) # map
out_50_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_50_debiased.RDS")
out_zero_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_zero_debiased.RDS")
n_samp = seq(1,100)
res = out_50_debiased[1:100]
# define ground truth
p = 10;
rho = 0.4
beta = diag(rho, p)
beta[abs(row(beta)-col(beta))==1] <- rho
coverage = function(active, true_beta, out_storm, n_samp, unit_id){
# select results of interest
b = length(n_samp)*unit_id #i.e. for unit_id = 1 b = 100
if(unit_id==1){
res = out_storm[1:b] #i.e. samples 1-100 for unit 1
}
if(unit_id!=1){
res = out_storm[((b-length(n_samp))+1):b]
}
true_beta = beta[unit_id,]
if(active==T){
s = which(true_beta!=0) # active set#
}
if(active==F){
s_c = which(true_beta==0)
s = s_c
}
lower = map(res, 3)
upper = map(res, 4)
truth = true_beta[s]
s_count = rep(0,length(truth)); s_count = rep(list(s_count), length(n_samp))
length_ci = rep(0, length(truth)); length_ci = rep(list(length_ci), length(n_samp))
for(i in 1:length(n_samp)){
lower_vals = lower[[i]][s]
upper_vals = upper[[i]][s]
for(j in 1:length(truth)){
if(truth[j]>lower_vals[j] & truth[j]<upper_vals[j]){s_count[[i]][j] = s_count[[i]][j] + 1}
}
# get lengths of CI
length_ci[[i]] = upper_vals-lower_vals
}
totals = unlist(lapply(s_count, sum))
avg_cov = sum(totals)/(length(n_samp)*length(s))
# lengths
t_length = unlist(lapply(length_ci, sum))
av_length = sum(t_length)/ (length(n_samp)*length(s))
return(list(cov = avg_cov, len = av_length))
}
get_avg_cov = function(true_beta, out, n_samp, p){
s_cov = NULL; sc_cov = NULL;
s_len = NULL; sc_len = NULL;
for(i in 1:p){
s_cov[i] = coverage(T, true_beta, out, n_samp, i)$cov
sc_cov[i] = coverage(F, true_beta, out, n_samp, i)$cov
s_len[i] = coverage(T, true_beta, out, n_samp, i)$len
sc_len[i] = coverage(F, true_beta, out, n_samp, i)$len
}
return(list(s_cov_mean = mean(s_cov), sc_cov_mean = mean(sc_cov), s_all = s_cov, sc_all = sc_cov, av_len_s = mean(s_len), av_len_sc = mean(sc_len)))
}
res_50 = get_avg_cov(true_beta, out_50_debiased, n_samp, p)
res_zero = get_avg_cov(true_beta, out_zero_debiased, n_samp, p)
df_50 = data.frame(s = res_50$s_all, sc=res_50$sc_all)
df_zero = data.frame(s = res_zero$s_all, sc=res_zero$sc_all)
par(mfrow=c(1,2))
boxplot(df_50, main = "50/50", ylim =c(0.85, 0.97))
boxplot(df_zero, main = "Zero-Inflated", ylim =c(0.85, 0.97))
out_ZI = c(res_zero$s_cov_mean, res_zero$sc_cov_mean, res_zero$av_len_s, res_zero$av_len_sc)
out_50 = c(res_50$s_cov_mean, res_50$sc_cov_mean, res_50$av_len_s, res_50$av_len_sc)
out = rbind(out_ZI, out_50)
colnames(out) = c("Avcov_s", "Avcov_sc", "Avlen_s", "Avlen_sc")
print(out)
library(purrr) # map
out_50_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_50_debiased.RDS")
out_zero_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_zero_debiased.RDS")
n_samp = seq(1,100)
res = out_50_debiased[1:100]
# define ground truth
p = 10;
rho = 0.4
beta = diag(rho, p)
beta[abs(row(beta)-col(beta))==1] <- rho
# select results of interest
b = length(n_samp)*unit_id #i.e. for unit_id = 1 b = 100
unit_id =1
# select results of interest
b = length(n_samp)*unit_id #i.e. for unit_id = 1 b = 100
if(unit_id==1){
res = out_storm[1:b] #i.e. samples 1-100 for unit 1
}
out_storm = out_50_debiased
if(unit_id==1){
res = out_storm[1:b] #i.e. samples 1-100 for unit 1
}
unit_id
true_beta = beta[unit_id,]
true_beta
s = which(true_beta!=0) # active set#
lower = map(res, 3)
upper = map(res, 4)
s_count = rep(0,length(truth)); s_count = rep(list(s_count), length(n_samp))
length_ci = rep(0, length(truth)); length_ci = rep(list(length_ci), length(n_samp))
truth = true_beta[s]
truth
s_count = rep(0,length(truth)); s_count = rep(list(s_count), length(n_samp))
length_ci = rep(0, length(truth)); length_ci = rep(list(length_ci), length(n_samp))
s_count
n_samp
for(i in 1:length(n_samp)){
lower_vals = lower[[i]][s]
upper_vals = upper[[i]][s]
for(j in 1:length(truth)){
if(truth[j]>lower_vals[j] & truth[j]<upper_vals[j]){s_count[[i]][j] = s_count[[i]][j] + 1}
}
# get lengths of CI
length_ci[[i]] = upper_vals-lower_vals
}
s_count
length(s)
print(out)
source("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/coverage.R")
cbind(out_ZI, out_50)
round(cbind(out_ZI, out_50),3)
source("~/.active-rstudio-document")
library(purrr) # map
library(splines) #bsplines
out_50_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_50_debiased.RDS") #1000 because 100 samples for each p (p=10)
p = 10; N_samp = 100
get_debiased_est = function(out_storm, p, N_samp){
# extract debiased lasso estimates for all dimensions
beta_deb = list(); beta_deb = rep(list(beta_deb), 100); beta_deb = rep(list(beta_deb), p);
for(i in 1:p){
b = N_samp*i
if(i==1){
res = out_storm[1:b] #i.e. samples 1-10 for lambda = 0.1
}
if(i!=1){
res = out_storm[((b-N_samp)+1):b]
}
# start with unit 1
res = out_50_debiased[1:100]
# betas for each sample
beta_deb[[i]] = map(res, 1)
}
return(beta_deb)
}
# get debiased estimates for each dimension
beta_debs = get_debiased_est(out_50_debiased, 10, 100)
data_50 <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Simulations/data_50.RDS")
y = data[idx,][2:9000] # use  8999 values
data = rep(data_50, p)
# Combine the lists into a list of pairs
list_of_pairs <- Map(list, data, unlist(beta_debs, recursive = F))
library(doParallel)
library(doRNG)
cl <- makeCluster(4)
start <- Sys.time()
registerDoParallel(cl)
registerDoRNG(seed = 123)
re_fit_50 <- foreach(k=list_of_pairs, .packages = c("purrr", "splines",
"LaplacesDemon")) %dopar%{
setwd("~/Downloads/GAPLA/Synthetic_Experiments")
source("Functions_GAPLA.R")
# read data
data = k[[1]]
beta_deb = k[[2]]
# do the re-fitting
re_fit_res = re_fit(data, idx=1, max_iter=1000, tol=1e-8, m=10, beta_deb)
return(list(beta_0 = re_fit_res$beta0, f_hat = re_fit_res$f_orig))
}
end <-Sys.time()
stopCluster(cl)
print(end-start)
beta_hats = map(re_fit_50, 1)
beta_0_hats = map(re_fit_50, 1)
rm(beta_hats)
N_samp
beta_0s = list(); beta_0s = rep(list(beta_0s),p)
for(i in 1:p){
b = N_samp*i
if(i==1){
beta_0s[[i]] = unlist(beta_0_hats[1:b])
}
if(i!=1){
beta_0s[[i]] = beta_0_hats[((b-N_samp)+1):b]
}
}
beta_0s = list(); beta_0s = rep(list(beta_0s),p)
for(i in 1:p){
b = N_samp*i
if(i==1){
beta_0s[[i]] = unlist(beta_0_hats[1:b])
}
if(i!=1){
beta_0s[[i]] = unlist(beta_0_hats[((b-N_samp)+1):b])
}
}
as.data.frame(beta_0s)
names(df)=seq(1,p)
df = as.data.frame(1 = beta_0s[[1]])
names(df)=seq(1,p)
boxplot(df)
df = as.data.frame(beta_0s)
boxplot(df)
names(df) =seq(1,p)
boxplot(df)
df$1 ==df$2
df$1 == df$2
df$1
df
all.equal(beta_0s)
beta_0s[[1]]
beta_0s[[1]] == beta_0s[[2]]
idx = c(rep(1,100), rep(2, 100), rep(3,100), rep(4,100), rep(5,100), rep(6,100), rep(7,100),
rep(8,100), rep(9,100), rep(10,100) )
idx[101:200]
list_of_trips <- Map(list, data, unlist(beta_debs, recursive = F), idx)
list_of_trips[[1]][[3]]
list_of_trips[[1]][3]
length(idx)
length(data)
length(unlist(beta_debs, recursive = F))
Map(list, c(1,2,3), matrix(NA, nrow=3,ncol=3), rep(1,10))
library(purrr) # map
library(splines) #bsplines
out_50_debiased <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Inference/out_50_debiased.RDS") #1000 because 100 samples for each p (p=10)
p = 10; N_samp = 100
get_debiased_est = function(out_storm, p, N_samp){
# extract debiased lasso estimates for all dimensions
beta_deb = list(); beta_deb = rep(list(beta_deb), 100); beta_deb = rep(list(beta_deb), p);
for(i in 1:p){
b = N_samp*i
if(i==1){
res = out_storm[1:b] #i.e. samples 1-10 for lambda = 0.1
}
if(i!=1){
res = out_storm[((b-N_samp)+1):b]
}
# start with unit 1
res = out_50_debiased[1:100]
# betas for each sample
beta_deb[[i]] = map(res, 1)
}
return(beta_deb)
}
# get debiased estimates for each dimension
beta_debs = get_debiased_est(out_50_debiased, 10, 100)
data_50 <- readRDS("~/Downloads/GAPLA/Synthetic_Experiments/Model_A/Simulations/data_50.RDS")
data = rep(data_50, p)
# Combine the lists into a list of pairs
list_of_pairs <- Map(list, data, unlist(beta_debs, recursive = F))
idx = c(rep(1,100), rep(2, 100), rep(3,100), rep(4,100), rep(5,100), rep(6,100), rep(7,100),
rep(8,100), rep(9,100), rep(10,100) )
list_of_trips <- Map(list, data, unlist(beta_debs, recursive = F), idx)
library(doParallel)
library(doRNG)
cl <- makeCluster(4)
start <- Sys.time()
registerDoParallel(cl)
registerDoRNG(seed = 123)
re_fit_50 <- foreach(k=list_of_trips, .packages = c("purrr", "splines",
"LaplacesDemon")) %dopar%{
setwd("~/Downloads/GAPLA/Synthetic_Experiments")
source("Functions_GAPLA.R")
# read data
data = k[[1]]
beta_deb = k[[2]]
idx = k[3]
# do the re-fitting
re_fit_res = re_fit(data, idx, max_iter=1000, tol=1e-8, m=10, beta_deb)
return(list(beta_0 = re_fit_res$beta0, f_hat = re_fit_res$f_orig))
}
library(splines)
check = bs(seq(1, 100), df=5, intercept = F)
dim(check)
length(phi[,1])
length(check[,1])
model1_times <- readRDS("~/luna/Paper_Code/Section 4/Reviews/Simulations/Simulated_Times/model1_times.RDS")
# Results from simulations -------------------------------------------
setwd("~/Downloads/RSE/4_Synthetic_Experiments")
source("Functions_Section_4.R")
library(purrr)
library(pracma) #for logspace
library(Matrix)
library(phonTools)
library(QZ)
library(purrr)
library(matrixStats)
library(complexplus)
library(psych)
library(pracma)
library(hawkes)
res1 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res1.RDS")
res2 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res2.RDS")
res3 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res3.RDS")
res4 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res4.RDS")
res5 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res5.RDS")
res6 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res6.RDS")
res7 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res7.RDS")
res8 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res8.RDS")
res9 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/10_trials/res9.RDS")
# get ground truth
P_vec = c(12,48,96)
ground_truth = Get_ground_truth(P_vec, 1, 0.0628)
gt_12 = map(ground_truth,1)
gt_48 = map(ground_truth,2)
gt_96 = map(ground_truth,3)
library(pROC)
metrics = function(res, gt){
theta_list = map(res, 1)
z_list = map(res, 2)
r = map(res, 3)
av_mse = mean( unlist(lapply(theta_list, function(x) performance_measures(x, gt$theta, F)$l2)) )
pc_list = lapply(z_list, partial_co)
F1 = mean(unlist(lapply(pc_list, function(x) performance_measures(x, gt$pc, T)$F1)))
# vectorise matrices for AUROC
true_pc = as.vector(gt$pc)
est_pc_vec = lapply(pc_list, as.vector)
# Check if the response has more than two levels
if (length(unique(true_pc)) > 2) {
roc_obj = lapply(est_pc_vec, function(x){multiclass.roc(true_pc, x, direction="<")})
auc_list = lapply(roc_obj, auc)
} else {
# Use roc for binary classification
roc_obj = lapply(est_pc_vec, function(x){roc(true_pc, x, direction="<")})
auc_list = lapply(roc_obj, auc)
}
auc_obj = mean(unlist(auc_list))
return(list(F1 = F1, av_mse = av_mse, av_AUC = auc_obj))
}
metrics(res1, gt_12)
metrics(res2, gt_48)
metrics(res3, gt_96)
ground_truth = Get_ground_truth(P_vec, 2, 0.0628)
gt_12 = map(ground_truth,1)
gt_48 = map(ground_truth,2)
gt_96 = map(ground_truth,3)
metrics(res4, gt_12)
metrics(res5, gt_48)
metrics(res6, gt_96)
metrics(res7, gt_12)
metrics(res8, gt_48)
metrics(res9, gt_96)
res1 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res1.RDS")
res2 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res2.RDS")
res3 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res3.RDS")
res4 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res4.RDS")
res5 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res5.RDS")
res6 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res6.RDS")
res7 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res7.RDS")
res8 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res8.RDS")
res9 <- readRDS("~/Downloads/RSE/4_Synthetic_Experiments/Graphical/Simulations/50_trials/res9.RDS")
# get ground truth
P_vec = c(12,48,96)
ground_truth = Get_ground_truth(P_vec, 1, 0.0628)
gt_12 = map(ground_truth,1)
gt_48 = map(ground_truth,2)
gt_96 = map(ground_truth,3)
metrics(res1, gt_12)
metrics(res2, gt_48)
metrics(res3, gt_96)
ground_truth = Get_ground_truth(P_vec, 2, 0.0628)
gt_12 = map(ground_truth,1)
gt_48 = map(ground_truth,2)
gt_96 = map(ground_truth,3)
metrics(res4, gt_12)
metrics(res5, gt_48)
metrics(res6, gt_96)
ground_truth = Get_ground_truth(P_vec, 3, 0.0628)
gt_12 = map(ground_truth,1)
gt_48 = map(ground_truth,2)
gt_96 = map(ground_truth,3)
metrics(res7, gt_12)
metrics(res8, gt_48)
metrics(res9, gt_96)
